{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":48.434265,"end_time":"2024-04-05T14:47:25.841756","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-05T14:46:37.407491","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"01c349150a544211bdaf52fe121be901":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8603016bc8ec4421995e41bdb1206578","placeholder":"‚Äã","style":"IPY_MODEL_272174f11d8c4a2f99e1122103e8a25c","value":"tokenizer_config.json: 100%"}},"0ea745decfc748b0bd6dc077def6fb7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17873f1d933f4d7bae4b019cd4aa95b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2660f345087040f69f8d36d566115ca1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6d144057fe5441fbd1e862187162190","placeholder":"‚Äã","style":"IPY_MODEL_d9edbf54860548828a006e094fbd2d83","value":" 232k/232k [00:00&lt;00:00, 3.32MB/s]"}},"272174f11d8c4a2f99e1122103e8a25c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"275fe2ef54974f4ab43f78f62996af5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2834084ae9b44440bf81647af3b40217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9797878f7a5341c4b4d0693a2b4ed5c0","placeholder":"‚Äã","style":"IPY_MODEL_9a20130218554433a082c0274e968b42","value":"vocab.txt: 100%"}},"298c18db4979473e8de04837b65a8f0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d007a0808c040c998f1a75e7280e91f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"314b505f9ecb44149c57168305f36f53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3493055252d24c31a8aee11f9582c171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8941e43585314970b466bc95eb96b2c2","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_298c18db4979473e8de04837b65a8f0e","value":231508}},"36aea6ea9ec843d6bdc37d493e87fa89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72f8f46df0ca42b0bd7872978e980a9c","IPY_MODEL_a404f18033c44f369a316f6f1a3d48d9","IPY_MODEL_d0207259d9e842dda8c33fd933176c24"],"layout":"IPY_MODEL_275fe2ef54974f4ab43f78f62996af5f"}},"38b959a9f6a3432c9f2722a3b4120f8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3edfd96e73ed46f78d7349b55c1cc238":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b185ceefa2cc4211aec525e95e9e1697","placeholder":"‚Äã","style":"IPY_MODEL_0ea745decfc748b0bd6dc077def6fb7d","value":"model.safetensors: 100%"}},"4752b44cae144652bf60063c7cbe5632":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01c349150a544211bdaf52fe121be901","IPY_MODEL_c25ab841bdc44f879bca11f5fb03556d","IPY_MODEL_753f2e3870574cd5af268f9e420bd0bf"],"layout":"IPY_MODEL_837e4b369db24034b08e65e0a9defe9d"}},"4aa85d953e804a829f0014011723e8c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b11726f2aa64bcfb20c606bd6c8146a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38b959a9f6a3432c9f2722a3b4120f8b","placeholder":"‚Äã","style":"IPY_MODEL_b386387b70a84b1b815e09eaa5c72030","value":" 268M/268M [00:01&lt;00:00, 187MB/s]"}},"72f8f46df0ca42b0bd7872978e980a9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2cf8e9f102a46099f53513f2711a346","placeholder":"‚Äã","style":"IPY_MODEL_fdf11266b48b4a158059ddc7cde62682","value":"config.json: 100%"}},"753f2e3870574cd5af268f9e420bd0bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d007a0808c040c998f1a75e7280e91f","placeholder":"‚Äã","style":"IPY_MODEL_dfc934c617274e278d9ebe05a76e3d08","value":" 48.0/48.0 [00:00&lt;00:00, 2.58kB/s]"}},"7647fbb531d24a4bbd6bbc9635d873a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3edfd96e73ed46f78d7349b55c1cc238","IPY_MODEL_d2c319f9f9824a8388570bb27a41eb2f","IPY_MODEL_6b11726f2aa64bcfb20c606bd6c8146a"],"layout":"IPY_MODEL_f3726584f834425a865b96ae6ecc8b0b"}},"837e4b369db24034b08e65e0a9defe9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8603016bc8ec4421995e41bdb1206578":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869b17ec1fa344e6bfe9d45461d63c1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8941e43585314970b466bc95eb96b2c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9797878f7a5341c4b4d0693a2b4ed5c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a20130218554433a082c0274e968b42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a404f18033c44f369a316f6f1a3d48d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17873f1d933f4d7bae4b019cd4aa95b0","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae558ddd72634a298a30adb895534e24","value":629}},"ae558ddd72634a298a30adb895534e24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b170e7b32fe6447dbdf7461a39cc406d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b185ceefa2cc4211aec525e95e9e1697":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b386387b70a84b1b815e09eaa5c72030":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c25ab841bdc44f879bca11f5fb03556d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_314b505f9ecb44149c57168305f36f53","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b170e7b32fe6447dbdf7461a39cc406d","value":48}},"c2daede3c50b4817be3572a2bc0d7663":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0207259d9e842dda8c33fd933176c24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4aa85d953e804a829f0014011723e8c6","placeholder":"‚Äã","style":"IPY_MODEL_869b17ec1fa344e6bfe9d45461d63c1b","value":" 629/629 [00:00&lt;00:00, 30.2kB/s]"}},"d0960f124f0e42f7b7f673e34126761f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2834084ae9b44440bf81647af3b40217","IPY_MODEL_3493055252d24c31a8aee11f9582c171","IPY_MODEL_2660f345087040f69f8d36d566115ca1"],"layout":"IPY_MODEL_e45ccb8142d14aa3aef1f5fbf47829cc"}},"d2c319f9f9824a8388570bb27a41eb2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0f0482500034261848f35cb334c5fc1","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2daede3c50b4817be3572a2bc0d7663","value":267832558}},"d6d144057fe5441fbd1e862187162190":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9edbf54860548828a006e094fbd2d83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfc934c617274e278d9ebe05a76e3d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0f0482500034261848f35cb334c5fc1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e45ccb8142d14aa3aef1f5fbf47829cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2cf8e9f102a46099f53513f2711a346":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3726584f834425a865b96ae6ecc8b0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdf11266b48b4a158059ddc7cde62682":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Utilisation des Transformers de Hugging Face ü§ó","metadata":{"papermill":{"duration":0.00618,"end_time":"2024-04-05T14:46:41.264293","exception":false,"start_time":"2024-04-05T14:46:41.258113","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# commencez par installer la biblioth√®que transformers si vous n'utilisez pas Colab ou Kaggle\n\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:50:17.057938Z","iopub.execute_input":"2024-05-26T16:50:17.058348Z","iopub.status.idle":"2024-05-26T16:50:29.846663Z","shell.execute_reply.started":"2024-05-26T16:50:17.058317Z","shell.execute_reply":"2024-05-26T16:50:29.845559Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocessing avec un Tokenizer","metadata":{"papermill":{"duration":0.005112,"end_time":"2024-04-05T14:46:41.275532","exception":false,"start_time":"2024-04-05T14:46:41.270420","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import AutoTokenizer    \n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"papermill":{"duration":10.542038,"end_time":"2024-04-05T14:46:51.822881","exception":false,"start_time":"2024-04-05T14:46:41.280843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:54:58.896381Z","iopub.execute_input":"2024-05-26T16:54:58.896815Z","iopub.status.idle":"2024-05-26T16:54:59.130407Z","shell.execute_reply.started":"2024-05-26T16:54:58.896783Z","shell.execute_reply":"2024-05-26T16:54:59.129240Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"raw_inputs = [\n    \"Burkina Faso is a West African country divided into 45 provinces.\",\n    \"The official language is French, but other national languages such as Moor√©, Peul, Dioula and Bissa are also spoken.\",\n]\n\ninputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\nprint(inputs)","metadata":{"papermill":{"duration":19.194406,"end_time":"2024-04-05T14:47:11.025015","exception":false,"start_time":"2024-04-05T14:46:51.830609","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:09.424493Z","iopub.execute_input":"2024-05-26T16:55:09.425458Z","iopub.status.idle":"2024-05-26T16:55:09.433612Z","shell.execute_reply.started":"2024-05-26T16:55:09.425423Z","shell.execute_reply":"2024-05-26T16:55:09.432621Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"{'input_ids': <tf.Tensor: shape=(2, 29), dtype=int32, numpy=\narray([[  101, 23089, 22773,  2003,  1037,  2225,  3060,  2406,  4055,\n         2046,  3429,  6941,  1012,   102,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0],\n       [  101,  1996,  2880,  2653,  2003,  2413,  1010,  2021,  2060,\n         2120,  4155,  2107,  2004,  5405,  1010, 21877,  5313,  1010,\n         4487,  7140,  2721,  1998, 20377,  3736,  2024,  2036,  5287,\n         1012,   102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 29), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Passer le mod√®le en revue","metadata":{"papermill":{"duration":0.009441,"end_time":"2024-04-05T14:47:11.045254","exception":false,"start_time":"2024-04-05T14:47:11.035813","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import TFAutoModel\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = TFAutoModel.from_pretrained(checkpoint)","metadata":{"papermill":{"duration":7.579935,"end_time":"2024-04-05T14:47:18.632869","exception":false,"start_time":"2024-04-05T14:47:11.052934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:15.890154Z","iopub.execute_input":"2024-05-26T16:55:15.890529Z","iopub.status.idle":"2024-05-26T16:55:17.603090Z","shell.execute_reply.started":"2024-05-26T16:55:15.890499Z","shell.execute_reply":"2024-05-26T16:55:17.602094Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFDistilBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Vecteur de grande dimension (High-dimensional vector) ?","metadata":{"papermill":{"duration":0.006687,"end_time":"2024-04-05T14:47:18.646787","exception":false,"start_time":"2024-04-05T14:47:18.640100","status":"completed"},"tags":[]}},{"cell_type":"code","source":"outputs = model(inputs)\nprint(outputs.last_hidden_state.shape)","metadata":{"papermill":{"duration":0.495429,"end_time":"2024-04-05T14:47:19.148862","exception":false,"start_time":"2024-04-05T14:47:18.653433","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:41.857815Z","iopub.execute_input":"2024-05-26T16:55:41.858651Z","iopub.status.idle":"2024-05-26T16:55:42.058683Z","shell.execute_reply.started":"2024-05-26T16:55:41.858613Z","shell.execute_reply":"2024-05-26T16:55:42.057598Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"(2, 29, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs[0]","metadata":{"papermill":{"duration":0.023537,"end_time":"2024-04-05T14:47:19.180610","exception":false,"start_time":"2024-04-05T14:47:19.157073","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:42.967115Z","iopub.execute_input":"2024-05-26T16:55:42.967759Z","iopub.status.idle":"2024-05-26T16:55:42.975604Z","shell.execute_reply.started":"2024-05-26T16:55:42.967728Z","shell.execute_reply":"2024-05-26T16:55:42.974554Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 29, 768), dtype=float32, numpy=\narray([[[-0.18444543,  0.18406054, -0.3317901 , ..., -0.33912918,\n          0.6345618 , -0.21481766],\n        [ 0.5576094 ,  0.5374135 , -0.26444602, ..., -0.6617011 ,\n          0.73083746, -0.58173436],\n        [ 0.33717203,  0.7582899 , -0.15661317, ..., -0.8102957 ,\n          0.37502262, -0.1652882 ],\n        ...,\n        [-0.22423077,  0.4882026 , -0.7373865 , ..., -0.35429463,\n          0.28613007, -0.8663359 ],\n        [ 0.16610484,  0.35079545, -0.37180883, ..., -0.44478616,\n          0.29429734, -0.6339572 ],\n        [-0.1446706 ,  0.31071886, -0.62418133, ..., -0.31383926,\n          0.15263262, -0.43699735]],\n\n       [[ 0.20606035,  0.767488  , -0.36321968, ..., -0.25143635,\n          0.46576267, -0.49673885],\n        [-0.22202978,  0.4234435 , -0.4924144 , ..., -0.00735636,\n          0.8536247 ,  0.3430001 ],\n        [-0.41844034,  0.65331614, -0.05087002, ..., -0.33773685,\n          0.93199396,  0.47552633],\n        ...,\n        [ 0.41537088,  1.1392596 , -0.03990367, ..., -0.07835131,\n          0.30962306, -0.7232689 ],\n        [ 0.9223254 ,  0.0381694 , -0.08765277, ...,  0.74142706,\n         -0.24472395, -0.29223117],\n        [ 0.16238059,  0.52012324, -0.52342016, ...,  0.3963744 ,\n          0.5045525 , -0.2511695 ]]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"markdown","source":"### T√™tes de mod√®le (Heads) : Donner du sens aux chiffres","metadata":{"papermill":{"duration":0.007031,"end_time":"2024-04-05T14:47:19.194931","exception":false,"start_time":"2024-04-05T14:47:19.187900","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import TFAutoModelForSequenceClassification  # ajout d'une tete pour la classification de s√©quences\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\noutputs = model(inputs)","metadata":{"papermill":{"duration":2.879514,"end_time":"2024-04-05T14:47:22.082790","exception":false,"start_time":"2024-04-05T14:47:19.203276","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:45.788283Z","iopub.execute_input":"2024-05-26T16:55:45.788677Z","iopub.status.idle":"2024-05-26T16:55:47.637190Z","shell.execute_reply.started":"2024-05-26T16:55:45.788646Z","shell.execute_reply":"2024-05-26T16:55:47.636139Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs.logits.shape","metadata":{"papermill":{"duration":0.023521,"end_time":"2024-04-05T14:47:22.116336","exception":false,"start_time":"2024-04-05T14:47:22.092815","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:47.639030Z","iopub.execute_input":"2024-05-26T16:55:47.639412Z","iopub.status.idle":"2024-05-26T16:55:47.646130Z","shell.execute_reply.started":"2024-05-26T16:55:47.639379Z","shell.execute_reply":"2024-05-26T16:55:47.645063Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TensorShape([2, 2])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Postprocessing outputs","metadata":{"papermill":{"duration":0.007355,"end_time":"2024-04-05T14:47:22.132669","exception":false,"start_time":"2024-04-05T14:47:22.125314","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(outputs.logits)","metadata":{"papermill":{"duration":0.021204,"end_time":"2024-04-05T14:47:22.162672","exception":false,"start_time":"2024-04-05T14:47:22.141468","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:57.730412Z","iopub.execute_input":"2024-05-26T16:55:57.730794Z","iopub.status.idle":"2024-05-26T16:55:57.736188Z","shell.execute_reply.started":"2024-05-26T16:55:57.730765Z","shell.execute_reply":"2024-05-26T16:55:57.735027Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[-1.6803675  1.6408637]\n [-1.7621164  1.7131441]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\npredictions = tf.math.softmax(outputs.logits, axis=-1)\nprint(predictions)","metadata":{"papermill":{"duration":0.022275,"end_time":"2024-04-05T14:47:22.193204","exception":false,"start_time":"2024-04-05T14:47:22.170929","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T16:55:57.907797Z","iopub.execute_input":"2024-05-26T16:55:57.908181Z","iopub.status.idle":"2024-05-26T16:55:57.915103Z","shell.execute_reply.started":"2024-05-26T16:55:57.908155Z","shell.execute_reply":"2024-05-26T16:55:57.913914Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[0.03484998 0.96515   ]\n [0.0300244  0.9699756 ]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Les Mod√®les sur ü§ó","metadata":{}},{"cell_type":"markdown","source":"## Creation d'un Transformer: le cas de BERT","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig, TFBertModel\n\n# the config\nconfig = BertConfig()\n\n# the model from the config\nmodel = TFBertModel(config)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:56:15.955887Z","iopub.execute_input":"2024-05-26T16:56:15.956246Z","iopub.status.idle":"2024-05-26T16:56:16.119728Z","shell.execute_reply.started":"2024-05-26T16:56:15.956222Z","shell.execute_reply":"2024-05-26T16:56:16.118632Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(config)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:56:16.958845Z","iopub.execute_input":"2024-05-26T16:56:16.959765Z","iopub.status.idle":"2024-05-26T16:56:16.965562Z","shell.execute_reply.started":"2024-05-26T16:56:16.959729Z","shell.execute_reply":"2024-05-26T16:56:16.964478Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"BertConfig {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.39.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### M√©thodes de chargement des mod√®les","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig, TFBertModel\n\nconfig = BertConfig()\nmodel = TFBertModel(config)\n\n# Ici les param√®tres du mod√®le seront initialis√©s al√©atoirement","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:56:41.591137Z","iopub.execute_input":"2024-05-26T16:56:41.591549Z","iopub.status.idle":"2024-05-26T16:56:41.747871Z","shell.execute_reply.started":"2024-05-26T16:56:41.591520Z","shell.execute_reply":"2024-05-26T16:56:41.746820Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from transformers import TFBertModel\n\n# ici on charge le mod√®le de base de BERT pr√©train√©\nmodel = TFBertModel.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:57:14.423029Z","iopub.execute_input":"2024-05-26T16:57:14.423873Z","iopub.status.idle":"2024-05-26T16:57:17.024460Z","shell.execute_reply.started":"2024-05-26T16:57:14.423819Z","shell.execute_reply":"2024-05-26T16:57:17.023396Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Enregistrer avec la m√©thode \"save_pretrained\"","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"mon_repertoire\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:59:17.462032Z","iopub.execute_input":"2024-05-26T16:59:17.462400Z","iopub.status.idle":"2024-05-26T16:59:18.520713Z","shell.execute_reply.started":"2024-05-26T16:59:17.462373Z","shell.execute_reply":"2024-05-26T16:59:18.519603Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# ls affiche tout simplement le contenu du r√©pertoire mon_repertoire\n\n!ls mon_repertoire","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:00:32.000772Z","iopub.execute_input":"2024-05-26T17:00:32.001190Z","iopub.status.idle":"2024-05-26T17:00:33.062919Z","shell.execute_reply.started":"2024-05-26T17:00:32.001161Z","shell.execute_reply":"2024-05-26T17:00:33.061550Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"config.json  tf_model.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Les Tokenizers sur ü§ó","metadata":{}},{"cell_type":"markdown","source":"## Loading and saving","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:14.924510Z","iopub.execute_input":"2024-05-26T17:02:14.924986Z","iopub.status.idle":"2024-05-26T17:02:15.168413Z","shell.execute_reply.started":"2024-05-26T17:02:14.924950Z","shell.execute_reply":"2024-05-26T17:02:15.167326Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:16.005465Z","iopub.execute_input":"2024-05-26T17:02:16.005865Z","iopub.status.idle":"2024-05-26T17:02:16.159116Z","shell.execute_reply.started":"2024-05-26T17:02:16.005809Z","shell.execute_reply":"2024-05-26T17:02:16.158138Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"tokenizer(\"Using a Transformer network is simple\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:17.033905Z","iopub.execute_input":"2024-05-26T17:02:17.034274Z","iopub.status.idle":"2024-05-26T17:02:17.042043Z","shell.execute_reply.started":"2024-05-26T17:02:17.034247Z","shell.execute_reply":"2024-05-26T17:02:17.040906Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"directory_on_my_computer\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:17.900794Z","iopub.execute_input":"2024-05-26T17:02:17.901799Z","iopub.status.idle":"2024-05-26T17:02:17.928956Z","shell.execute_reply.started":"2024-05-26T17:02:17.901761Z","shell.execute_reply":"2024-05-26T17:02:17.927872Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"('directory_on_my_computer/tokenizer_config.json',\n 'directory_on_my_computer/special_tokens_map.json',\n 'directory_on_my_computer/vocab.txt',\n 'directory_on_my_computer/added_tokens.json',\n 'directory_on_my_computer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\nsequence = \"Using a Transformer network is simple\"\ntokens = tokenizer.tokenize(sequence)\n\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:21.193298Z","iopub.execute_input":"2024-05-26T17:02:21.193694Z","iopub.status.idle":"2024-05-26T17:02:21.351002Z","shell.execute_reply.started":"2024-05-26T17:02:21.193663Z","shell.execute_reply":"2024-05-26T17:02:21.349929Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### From tokens to input IDs","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:48:25.872339Z","iopub.execute_input":"2024-05-26T16:48:25.873307Z","iopub.status.idle":"2024-05-26T16:48:25.877524Z","shell.execute_reply.started":"2024-05-26T16:48:25.873271Z","shell.execute_reply":"2024-05-26T16:48:25.876363Z"}}},{"cell_type":"code","source":"ids = tokenizer.convert_tokens_to_ids(tokens)\n\nprint(ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:21.498092Z","iopub.execute_input":"2024-05-26T17:02:21.498479Z","iopub.status.idle":"2024-05-26T17:02:21.503820Z","shell.execute_reply.started":"2024-05-26T17:02:21.498451Z","shell.execute_reply":"2024-05-26T17:02:21.502588Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"[7993, 170, 13809, 23763, 2443, 1110, 3014]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Decoding","metadata":{}},{"cell_type":"code","source":"decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n\nprint(decoded_string)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:02:24.696284Z","iopub.execute_input":"2024-05-26T17:02:24.696645Z","iopub.status.idle":"2024-05-26T17:02:24.703264Z","shell.execute_reply.started":"2024-05-26T17:02:24.696618Z","shell.execute_reply":"2024-05-26T17:02:24.702051Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Using a transformer network is simple\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4. Gestion des s√©quences multiples ü§ó","metadata":{}},{"cell_type":"markdown","source":"## Les mod√®les attendent un batch (lot) d'entr√©es par d√©faut","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\ninput_ids = tf.constant(ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:45.703626Z","iopub.execute_input":"2024-05-26T17:03:45.704071Z","iopub.status.idle":"2024-05-26T17:03:47.701777Z","shell.execute_reply.started":"2024-05-26T17:03:45.704040Z","shell.execute_reply":"2024-05-26T17:03:47.700707Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"ids","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:47.703442Z","iopub.execute_input":"2024-05-26T17:03:47.703761Z","iopub.status.idle":"2024-05-26T17:03:47.710194Z","shell.execute_reply.started":"2024-05-26T17:03:47.703734Z","shell.execute_reply":"2024-05-26T17:03:47.709177Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"[1045,\n 1005,\n 2310,\n 2042,\n 3403,\n 2005,\n 1037,\n 17662,\n 12172,\n 2607,\n 2026,\n 2878,\n 2166,\n 1012]"},"metadata":{}}]},{"cell_type":"code","source":"input_ids","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:48.755981Z","iopub.execute_input":"2024-05-26T17:03:48.756376Z","iopub.status.idle":"2024-05-26T17:03:48.763750Z","shell.execute_reply.started":"2024-05-26T17:03:48.756346Z","shell.execute_reply":"2024-05-26T17:03:48.762585Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(14,), dtype=int32, numpy=\narray([ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n        2607,  2026,  2878,  2166,  1012], dtype=int32)>"},"metadata":{}}]},{"cell_type":"code","source":"# This line will fail.\n\nmodel(input_ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:52.770854Z","iopub.execute_input":"2024-05-26T17:03:52.771241Z","iopub.status.idle":"2024-05-26T17:03:52.919320Z","shell.execute_reply.started":"2024-05-26T17:03:52.771212Z","shell.execute_reply":"2024-05-26T17:03:52.918235Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-2.7276218,  2.8789387]], dtype=float32)>, hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_inputs = tokenizer(sequence, return_tensors=\"tf\")\n\nprint(tokenized_inputs[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:53.822001Z","iopub.execute_input":"2024-05-26T17:03:53.822848Z","iopub.status.idle":"2024-05-26T17:03:53.829559Z","shell.execute_reply.started":"2024-05-26T17:03:53.822793Z","shell.execute_reply":"2024-05-26T17:03:53.828188Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[  101  1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026\n   2878  2166  1012   102]], shape=(1, 16), dtype=int32)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\n\ninput_ids = tf.constant([ids])\nprint(\"Input IDs:\", input_ids)\n\noutput = model(input_ids)\nprint(\"Logits:\", output.logits)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:55.113441Z","iopub.execute_input":"2024-05-26T17:03:55.116189Z","iopub.status.idle":"2024-05-26T17:03:57.123666Z","shell.execute_reply.started":"2024-05-26T17:03:55.116138Z","shell.execute_reply":"2024-05-26T17:03:57.122593Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Input IDs: tf.Tensor(\n[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878\n   2166  1012]], shape=(1, 14), dtype=int32)\nLogits: tf.Tensor([[-2.7276218  2.8789387]], shape=(1, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"batched_ids = [ids, ids]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:57.125477Z","iopub.execute_input":"2024-05-26T17:03:57.125796Z","iopub.status.idle":"2024-05-26T17:03:57.132970Z","shell.execute_reply.started":"2024-05-26T17:03:57.125769Z","shell.execute_reply":"2024-05-26T17:03:57.131849Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"input_ids = tf.constant(batched_ids)\nprint(\"Input IDs:\", input_ids)\n\noutput = model(input_ids)\nprint(\"Logits:\", output.logits)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:57.788816Z","iopub.execute_input":"2024-05-26T17:03:57.789607Z","iopub.status.idle":"2024-05-26T17:03:57.977333Z","shell.execute_reply.started":"2024-05-26T17:03:57.789571Z","shell.execute_reply":"2024-05-26T17:03:57.976068Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Input IDs: tf.Tensor(\n[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878\n   2166  1012]\n [ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878\n   2166  1012]], shape=(2, 14), dtype=int32)\nLogits: tf.Tensor(\n[[-2.7276225  2.8789396]\n [-2.727621   2.878938 ]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Putting it all together ü§ó","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:12:23.410083Z","iopub.execute_input":"2024-05-26T17:12:23.410462Z","iopub.status.idle":"2024-05-26T17:12:23.415174Z","shell.execute_reply.started":"2024-05-26T17:12:23.410435Z","shell.execute_reply":"2024-05-26T17:12:23.413983Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"sequence = \"Burkina Faso is a West African country divided into 45 provinces.\"\n\nsequences_multiples = [\n    \"Burkina Faso is a West African country divided into 45 provinces.\",\n    \"The official language is French, but other national languages such as Moor√©, Peul, Dioula and Bissa are also spoken.\",\n]\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:12:25.923702Z","iopub.execute_input":"2024-05-26T17:12:25.924113Z","iopub.status.idle":"2024-05-26T17:12:25.928951Z","shell.execute_reply.started":"2024-05-26T17:12:25.924075Z","shell.execute_reply":"2024-05-26T17:12:25.927783Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# passer une seule s√©quence au mod√®le\nmodel_inputs = tokenizer(sequence)\nmodel_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:12:58.852115Z","iopub.execute_input":"2024-05-26T17:12:58.853005Z","iopub.status.idle":"2024-05-26T17:12:59.121563Z","shell.execute_reply.started":"2024-05-26T17:12:58.852963Z","shell.execute_reply":"2024-05-26T17:12:59.120453Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"# passer plusieurs s√©quences au mod√®le\nmodel_inputs = tokenizer(sequences_multiples)\nmodel_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:13:10.251635Z","iopub.execute_input":"2024-05-26T17:13:10.252049Z","iopub.status.idle":"2024-05-26T17:13:10.260384Z","shell.execute_reply.started":"2024-05-26T17:13:10.252010Z","shell.execute_reply":"2024-05-26T17:13:10.259146Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[101, 23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012, 102], [101, 1996, 2880, 2653, 2003, 2413, 1010, 2021, 2060, 2120, 4155, 2107, 2004, 5405, 1010, 21877, 5313, 1010, 4487, 7140, 2721, 1998, 20377, 3736, 2024, 2036, 5287, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"code","source":"# Les s√©quences seront remplies jusqu'√† la longueur maximale de la s√©quence.\nmodel_inputs = tokenizer(sequences, padding=\"longest\")\n\n# Remplit les s√©quences jusqu'√† la longueur maximale du mod√®le\n# (512 pour BERT ou DistilBERT)\nmodel_inputs = tokenizer(sequences, padding=\"max_length\")\n\n# Remplit les s√©quences jusqu'√† la longueur maximale sp√©cifi√©e.\nmodel_inputs = tokenizer(sequences, padding=\"max_length\", max_length=8)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:15:32.200035Z","iopub.execute_input":"2024-05-26T17:15:32.200502Z","iopub.status.idle":"2024-05-26T17:15:32.207634Z","shell.execute_reply.started":"2024-05-26T17:15:32.200475Z","shell.execute_reply":"2024-05-26T17:15:32.206526Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"## Les Tokens sp√©ciaux","metadata":{}},{"cell_type":"code","source":"model_inputs = tokenizer(sequence)\nprint(model_inputs[\"input_ids\"])\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\nprint(ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:15:57.836271Z","iopub.execute_input":"2024-05-26T17:15:57.836668Z","iopub.status.idle":"2024-05-26T17:15:57.844466Z","shell.execute_reply.started":"2024-05-26T17:15:57.836638Z","shell.execute_reply":"2024-05-26T17:15:57.842986Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"[101, 23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012, 102]\n[23089, 22773, 2003, 1037, 2225, 3060, 2406, 4055, 2046, 3429, 6941, 1012]\n","output_type":"stream"}]},{"cell_type":"code","source":"# en r√©sum√© \n\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\ntokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\ninput_ids = tf.constant(ids)","metadata":{},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"2024-04-05 22:52:47.197617: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\n2024-04-05 22:52:47.197888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\n2024-04-05 22:52:47.370569: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20f1fbb8b547481eace1c33468ebe58e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15f1b21569fb44dfa1b17fcda892a10c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e7a65a9237e4103ba485399ffa5af5a","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b050498913334ea38c90ad4bcc80d8e9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{}},{"name":"stderr","output_type":"stream","text":"All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n\n\n\nAll the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"}]}]}