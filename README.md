<div align="center">
  <h1> Stage IA Selever - Cours & Projets - GO AI Corp; by</h1>
  <p align="center">
    üï∏ <a href="https://www.linkedin.com/in/anyantudre">LinkedIn</a> ‚Ä¢ 
    üìô <a href="https://www.kaggle.com/waalbannyantudre">Kaggle</a> ‚Ä¢ 
    üíª <a href="https://anyantudre.medium.com/">Medium Blog</a> ‚Ä¢ 
    ü§ó <a href="https://huggingface.co/anyantudre">Hugging Face</a> ‚Ä¢ 
  </p>
</div>
<br/>


Ce repo GitHub contient toutes les ressources et projets que nous avons utilis√©s et impl√©ment√©s dans le cadre du stage IA (projet Selever).

Ce stage est focalis√© sur le **Natural Language Processing (NLP)** avec des librairies commes **Hugging Face ü§ó transformers**, **Keras** et **Tensorflow**:
-  **Les Mini-Projets**, 
-  **Les supports de Cours**,
-  **Les Ressources √† consulter absolument**, et
-  **Les Ressources suppl√©mentaires √† approfondir vos connaissances**



# Repository structure

Les r√©pertoires de ce repo sont organis√©s comme suit :  

## 1. Projets & Applications Pratiques

| Title | Description  | Notebook |
|---------------------------------------|-------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| **1. Transformers, what can they do?** | Look at what Transformer models can do and use our first tool from the ü§ó Transformers library: the `pipeline()` function. | <a href="https://www.kaggle.com/code/waalbannyantudre/transformers-models-the-pipeline-function/notebook"> <img src="img/kaggle2.svg" alt="Open In "></a> |
| **2. How do Transformers work?** | High-level look at the architecture of Transformer models. | <a href=""> <img src="img/kaggle2.svg" alt="Open In "></a> |
| **3. Encoder, Decoders, Encoder-Decoder models** | Learn more about Encoder, Decoders, Encoder-Decoder models  | <a href=""> <img src="img/kaggle2.svg" alt="Open In "></a> |



  
### üõë Disclaimer ‚ùå: 
This is by no means intended to replace the original course.
If you're new to Transformers and Hugging Face, it would be best to refer to the latter, or at least have some basic knowledge of Deep Learning, particularly NLP.
The aim is to have a few notes from the course and the code snippets that seem most important to me to keep to hand in each part. Like a sort of cheat sheet to refresh your memory on the most important concepts to remember.
If you've already taken the original course, or have some basic knowledge of Transformers, you'll no doubt find this useful as a quick refresher on the various concepts.


### Original course:

- **License:** The original course is released under the permissive [Apache 2 license](https://www.apache.org/licenses/LICENSE-2.0.html).
- **Citation:**
```@misc{huggingfacecourse,
  author = {Hugging Face},
  title = {The Hugging Face Course, 2022},
  howpublished = "\url{https://huggingface.co/course}",
  year = {2022},
  note = "[Online; accessed <today>]"
}
```
